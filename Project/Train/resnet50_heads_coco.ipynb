{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the heads with resnet 50 as backbone and initial weights as coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Weights:  coco\n",
      "Dataset:  /home/ec2-user/SageMaker/Image_segmentation/samples/Data\n",
      "Logs:  /home/ec2-user/SageMaker/Image_segmentation/logs\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.6\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                16\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           pcd\n",
      "NUM_CLASSES                    4\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                75\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  /home/ec2-user/SageMaker/Image_segmentation/mask_rcnn_coco.h5\n",
      "2019-04-25 20:30:25.336341: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n",
      "Training network heads\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /home/ec2-user/SageMaker/Image_segmentation/logs/pcd20190425T2030/mask_rcnn_pcd_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow_p36/lib/python3.6/site-packages/keras/engine/training_generator.py:47: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n",
      "Epoch 1/5\n",
      "75/75 [==============================] - 2090s 28s/step - loss: 1.8895 - rpn_class_loss: 0.0158 - rpn_bbox_loss: 0.4883 - mrcnn_class_loss: 0.2611 - mrcnn_bbox_loss: 0.5790 - mrcnn_mask_loss: 0.5452 - val_loss: 2.2148 - val_rpn_class_loss: 0.0166 - val_rpn_bbox_loss: 0.9611 - val_mrcnn_class_loss: 0.1843 - val_mrcnn_bbox_loss: 0.6311 - val_mrcnn_mask_loss: 0.4216\n",
      "Epoch 2/5\n",
      "75/75 [==============================] - 2073s 28s/step - loss: 1.3497 - rpn_class_loss: 0.0157 - rpn_bbox_loss: 0.4345 - mrcnn_class_loss: 0.1280 - mrcnn_bbox_loss: 0.3732 - mrcnn_mask_loss: 0.3984 - val_loss: 1.6327 - val_rpn_class_loss: 0.0117 - val_rpn_bbox_loss: 0.4847 - val_mrcnn_class_loss: 0.2315 - val_mrcnn_bbox_loss: 0.5525 - val_mrcnn_mask_loss: 0.3522\n",
      "Epoch 3/5\n",
      "75/75 [==============================] - 2068s 28s/step - loss: 1.3197 - rpn_class_loss: 0.0134 - rpn_bbox_loss: 0.4583 - mrcnn_class_loss: 0.1123 - mrcnn_bbox_loss: 0.3984 - mrcnn_mask_loss: 0.3372 - val_loss: 1.9134 - val_rpn_class_loss: 0.0123 - val_rpn_bbox_loss: 0.8290 - val_mrcnn_class_loss: 0.1553 - val_mrcnn_bbox_loss: 0.6685 - val_mrcnn_mask_loss: 0.2483\n",
      "Epoch 4/5\n",
      "75/75 [==============================] - 2068s 28s/step - loss: 1.4395 - rpn_class_loss: 0.0074 - rpn_bbox_loss: 0.6688 - mrcnn_class_loss: 0.1087 - mrcnn_bbox_loss: 0.3432 - mrcnn_mask_loss: 0.3114 - val_loss: 1.7356 - val_rpn_class_loss: 0.0134 - val_rpn_bbox_loss: 0.5087 - val_mrcnn_class_loss: 0.1859 - val_mrcnn_bbox_loss: 0.6346 - val_mrcnn_mask_loss: 0.3931\n",
      "Epoch 5/5\n",
      "75/75 [==============================] - 2066s 28s/step - loss: 0.9591 - rpn_class_loss: 0.0148 - rpn_bbox_loss: 0.2412 - mrcnn_class_loss: 0.1253 - mrcnn_bbox_loss: 0.2952 - mrcnn_mask_loss: 0.2826 - val_loss: 1.4239 - val_rpn_class_loss: 0.0105 - val_rpn_bbox_loss: 0.3093 - val_mrcnn_class_loss: 0.2421 - val_mrcnn_bbox_loss: 0.5024 - val_mrcnn_mask_loss: 0.3595\n"
     ]
    }
   ],
   "source": [
    "#training heads, weights = coco, backbone = resnet50\n",
    "!python main.py train --dataset=\"/home/ec2-user/SageMaker/Image_segmentation/samples/Data\" --weights=coco"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
